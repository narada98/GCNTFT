{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_forecasting.models import TemporalFusionTransformer\n",
    "from pytorch_forecasting.data import TimeSeriesDataSet, GroupNormalizer\n",
    "from pytorch_forecasting.metrics import QuantileLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_path = \"/home/naradalinux/dev/GCNTFT/data/processed/data_w_geo_v3.csv\"\n",
    "embeddings_path = \"/home/naradalinux/dev/GCNTFT/data/embeddings_v2/tft_ready_embeddings.csv\"\n",
    "\n",
    "# Load the air quality data\n",
    "air_quality_df = pd.read_csv(data_path)\n",
    "air_quality_df['datetime'] = pd.to_datetime(air_quality_df['datetime'])\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings_df = pd.read_csv(embeddings_path, index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert the datetime to proper format for TimeSeriesDataSet\n",
    "air_quality_df['time_idx'] = (air_quality_df['datetime'] - air_quality_df['datetime'].min()).dt.total_seconds() // 3600\n",
    "air_quality_df['time_idx'] = air_quality_df['time_idx'].astype(int)\n",
    "air_quality_df = air_quality_df.sort_values(['station_loc', 'time_idx'])\n",
    "\n",
    "# Add a group_id column (required for pytorch-forecasting)\n",
    "station_ids = air_quality_df['station_loc'].unique()\n",
    "station_mapping = {station: idx for idx, station in enumerate(station_ids)}\n",
    "air_quality_df['group_id'] = air_quality_df['station_loc'].map(station_mapping)\n",
    "\n",
    "necessary_columns = ['datetime', 'time_idx', 'PM2.5 (ug/m3)', 'latitude', 'longitude', 'station_loc', 'group_id']\n",
    "air_quality_df = air_quality_df[necessary_columns]\n",
    "air_quality_df.rename(columns={'PM2.5 (ug/m3)': 'PM25'}, inplace=True)\n",
    "# air_quality_df['station_loc'] = air_quality_df['station_loc'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merge embeddings with the air quality data\n",
    "# # First, create a column for the embedding index\n",
    "# max_time_idx = air_quality_df['time_idx'].max()\n",
    "# window_size = 24  # assuming 24-hour window size used in GNN\n",
    "\n",
    "# # We need to match embeddings to the right time points\n",
    "# processed_data = []\n",
    "\n",
    "# for station in station_ids:\n",
    "#     station_data = air_quality_df[air_quality_df['station_loc'] == station]\n",
    "    \n",
    "#     # For each time point with sufficient history\n",
    "#     for t in range(window_size, int(max_time_idx) + 1):\n",
    "#         if t in station_data['time_idx'].values:\n",
    "#             curr_data = station_data[station_data['time_idx'] == t].iloc[0].to_dict()\n",
    "            \n",
    "#             # Find the embedding for this station at this time point\n",
    "#             station_idx = station_mapping[station]\n",
    "#             embedding_idx = (t - window_size) * len(station_ids) + station_idx\n",
    "            \n",
    "#             if embedding_idx < len(embeddings_df):\n",
    "#                 # Add embedding features\n",
    "#                 for i in range(1, embeddings_df.shape[1]):\n",
    "#                     curr_data[f'embedding_{i}'] = embeddings_df.iloc[embedding_idx, i]\n",
    "                \n",
    "#                 processed_data.append(curr_data)\n",
    "\n",
    "# # Create new dataframe with embeddings\n",
    "# combined_df = pd.DataFrame(processed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_df.to_csv(\"/home/naradalinux/dev/GCNTFT/data/processed/data_w_geo_v4.csv\", index=False)\n",
    "combined_df = pd.read_csv(\"/home/naradalinux/dev/GCNTFT/data/processed/data_w_geo_v4.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>PM25</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>station_loc</th>\n",
       "      <th>group_id</th>\n",
       "      <th>embedding_1</th>\n",
       "      <th>embedding_2</th>\n",
       "      <th>embedding_3</th>\n",
       "      <th>...</th>\n",
       "      <th>embedding_23</th>\n",
       "      <th>embedding_24</th>\n",
       "      <th>embedding_25</th>\n",
       "      <th>embedding_26</th>\n",
       "      <th>embedding_27</th>\n",
       "      <th>embedding_28</th>\n",
       "      <th>embedding_29</th>\n",
       "      <th>embedding_30</th>\n",
       "      <th>embedding_31</th>\n",
       "      <th>embedding_32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-01 23:00:00</td>\n",
       "      <td>24</td>\n",
       "      <td>174.0</td>\n",
       "      <td>28.797312</td>\n",
       "      <td>77.138667</td>\n",
       "      <td>Alipur, Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.659644</td>\n",
       "      <td>0.973403</td>\n",
       "      <td>0.950521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360108</td>\n",
       "      <td>0.385222</td>\n",
       "      <td>0.904384</td>\n",
       "      <td>-0.391190</td>\n",
       "      <td>0.533015</td>\n",
       "      <td>-0.898249</td>\n",
       "      <td>0.586380</td>\n",
       "      <td>0.378052</td>\n",
       "      <td>0.627379</td>\n",
       "      <td>0.274174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-02 00:00:00</td>\n",
       "      <td>25</td>\n",
       "      <td>160.0</td>\n",
       "      <td>28.797312</td>\n",
       "      <td>77.138667</td>\n",
       "      <td>Alipur, Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.734946</td>\n",
       "      <td>0.956723</td>\n",
       "      <td>0.985116</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432373</td>\n",
       "      <td>0.514372</td>\n",
       "      <td>0.977635</td>\n",
       "      <td>-0.340597</td>\n",
       "      <td>0.729516</td>\n",
       "      <td>-0.851131</td>\n",
       "      <td>0.709411</td>\n",
       "      <td>0.474948</td>\n",
       "      <td>0.612100</td>\n",
       "      <td>0.440182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-02 01:00:00</td>\n",
       "      <td>26</td>\n",
       "      <td>139.0</td>\n",
       "      <td>28.797312</td>\n",
       "      <td>77.138667</td>\n",
       "      <td>Alipur, Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.758993</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.927283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.405998</td>\n",
       "      <td>0.582113</td>\n",
       "      <td>0.883297</td>\n",
       "      <td>-0.208380</td>\n",
       "      <td>0.772565</td>\n",
       "      <td>-0.808870</td>\n",
       "      <td>0.679129</td>\n",
       "      <td>0.457232</td>\n",
       "      <td>0.410480</td>\n",
       "      <td>0.534738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-02 02:00:00</td>\n",
       "      <td>27</td>\n",
       "      <td>156.0</td>\n",
       "      <td>28.797312</td>\n",
       "      <td>77.138667</td>\n",
       "      <td>Alipur, Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.691837</td>\n",
       "      <td>0.459378</td>\n",
       "      <td>0.813349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223756</td>\n",
       "      <td>0.533677</td>\n",
       "      <td>0.677830</td>\n",
       "      <td>0.001629</td>\n",
       "      <td>0.582883</td>\n",
       "      <td>-0.752520</td>\n",
       "      <td>0.476877</td>\n",
       "      <td>0.226231</td>\n",
       "      <td>-0.004298</td>\n",
       "      <td>0.443733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-02 03:00:00</td>\n",
       "      <td>28</td>\n",
       "      <td>157.0</td>\n",
       "      <td>28.797312</td>\n",
       "      <td>77.138667</td>\n",
       "      <td>Alipur, Delhi</td>\n",
       "      <td>0</td>\n",
       "      <td>0.719003</td>\n",
       "      <td>0.367890</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>0.630484</td>\n",
       "      <td>0.498522</td>\n",
       "      <td>0.134125</td>\n",
       "      <td>0.480636</td>\n",
       "      <td>-0.813771</td>\n",
       "      <td>0.358310</td>\n",
       "      <td>0.148527</td>\n",
       "      <td>-0.315213</td>\n",
       "      <td>0.483661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              datetime  time_idx   PM25   latitude  longitude     station_loc  \\\n",
       "0  2022-04-01 23:00:00        24  174.0  28.797312  77.138667  Alipur, Delhi    \n",
       "1  2022-04-02 00:00:00        25  160.0  28.797312  77.138667  Alipur, Delhi    \n",
       "2  2022-04-02 01:00:00        26  139.0  28.797312  77.138667  Alipur, Delhi    \n",
       "3  2022-04-02 02:00:00        27  156.0  28.797312  77.138667  Alipur, Delhi    \n",
       "4  2022-04-02 03:00:00        28  157.0  28.797312  77.138667  Alipur, Delhi    \n",
       "\n",
       "   group_id  embedding_1  embedding_2  embedding_3  ...  embedding_23  \\\n",
       "0         0     0.659644     0.973403     0.950521  ...      0.360108   \n",
       "1         0     0.734946     0.956723     0.985116  ...      0.432373   \n",
       "2         0     0.758993     0.771369     0.927283  ...      0.405998   \n",
       "3         0     0.691837     0.459378     0.813349  ...      0.223756   \n",
       "4         0     0.719003     0.367890     0.719558  ...      0.195613   \n",
       "\n",
       "   embedding_24  embedding_25  embedding_26  embedding_27  embedding_28  \\\n",
       "0      0.385222      0.904384     -0.391190      0.533015     -0.898249   \n",
       "1      0.514372      0.977635     -0.340597      0.729516     -0.851131   \n",
       "2      0.582113      0.883297     -0.208380      0.772565     -0.808870   \n",
       "3      0.533677      0.677830      0.001629      0.582883     -0.752520   \n",
       "4      0.630484      0.498522      0.134125      0.480636     -0.813771   \n",
       "\n",
       "   embedding_29  embedding_30  embedding_31  embedding_32  \n",
       "0      0.586380      0.378052      0.627379      0.274174  \n",
       "1      0.709411      0.474948      0.612100      0.440182  \n",
       "2      0.679129      0.457232      0.410480      0.534738  \n",
       "3      0.476877      0.226231     -0.004298      0.443733  \n",
       "4      0.358310      0.148527     -0.315213      0.483661  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prediction parameters\n",
    "max_prediction_length = 24  # predict 24 hours into the future\n",
    "max_encoder_length = 72     # use 72 hours of history\n",
    "\n",
    "# Create training dataset\n",
    "training_cutoff = combined_df[\"time_idx\"].max() - max_prediction_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8736"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['station_loc'] = combined_df['station_loc'].astype('category')\n",
    "# combined_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_groups = np.array_split(station_ids, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Alipur, Delhi ', 'Anand Vihar, Delhi ', 'Ashok Vihar, Delhi ',\n",
       "        'Aya Nagar, Delhi ', 'Bawana, Delhi ', 'Burari Crossing, Delhi ',\n",
       "        'CRRI Mathura Road, Delhi ', 'Chandni Chowk, Delhi '], dtype=object),\n",
       " array(['DTU, Delhi ', 'Dr. Karni Singh Shooting Range, Delhi ',\n",
       "        'Dwarka Sector 8, Delhi ', 'East Arjun Nagar, Delhi ',\n",
       "        'IGI Airport (T3), Delhi ', 'IHBAS, Dilshad Garden, Delhi ',\n",
       "        'ITO, Delhi ', 'Jahangirpuri, Delhi '], dtype=object),\n",
       " array(['Jawaharlal Nehru Stadium, Delhi ', 'Lodhi Road, Delhi ',\n",
       "        'Major Dhyan Chand National Stadium, Delhi ',\n",
       "        'Mandir Marg, Delhi ', 'Mundka, Delhi ', 'NSIT Dwarka, Delhi ',\n",
       "        'Najafgarh, Delhi '], dtype=object),\n",
       " array(['Narela, Delhi ', 'Nehru Nagar, Delhi ',\n",
       "        'North Campus, DU, Delhi ', 'Okhla Phase 2, Delhi ',\n",
       "        'Patparganj, Delhi ', 'Punjabi Bagh, Delhi ', 'Pusa, Delhi '],\n",
       "       dtype=object),\n",
       " array(['R K Puram, Delhi ', 'Rohini, Delhi ', 'Shadipur, Delhi ',\n",
       "        'Sonia Vihar, Delhi ', 'Sri Aurobindo Marg, Delhi ',\n",
       "        'Vivek Vihar, Delhi ', 'Wazirpur, Delhi '], dtype=object)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset\n",
    "tft_dataset = TimeSeriesDataSet(\n",
    "    data=combined_df[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"PM25\",\n",
    "    group_ids=[\"group_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # allow for smaller encoder lengths\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"station_loc\"],\n",
    "    static_reals=[\"latitude\", \"longitude\"],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"PM25\",\n",
    "    ] + [f'embedding_{i}' for i in range(1, embeddings_df.shape[1])],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"group_id\"], transformation=\"softplus\"\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = tft_dataset.to_dataloader(train=True, batch_size=batch_size, num_workers=4)\n",
    "val_dataloader = tft_dataset.to_dataloader(train=False, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'loss' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['loss'])`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/utilities/parsing.py:209: Attribute 'logging_metrics' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['logging_metrics'])`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformer(\n",
       "  \t\"attention_head_size\":               1\n",
       "  \t\"categorical_groups\":                {}\n",
       "  \t\"causal_attention\":                  True\n",
       "  \t\"dataset_parameters\":                {'time_idx': 'time_idx', 'target': 'PM25', 'group_ids': ['group_id'], 'weight': None, 'max_encoder_length': 72, 'min_encoder_length': 36, 'min_prediction_idx': 24, 'min_prediction_length': 1, 'max_prediction_length': 24, 'static_categoricals': ['station_loc'], 'static_reals': ['latitude', 'longitude'], 'time_varying_known_categoricals': [], 'time_varying_known_reals': ['time_idx'], 'time_varying_unknown_categoricals': [], 'time_varying_unknown_reals': ['PM25', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32'], 'variable_groups': None, 'constant_fill_strategy': None, 'allow_missing_timesteps': False, 'lags': None, 'add_relative_time_idx': True, 'add_target_scales': True, 'add_encoder_length': True, 'target_normalizer': GroupNormalizer(\n",
       "  \t\tmethod='standard',\n",
       "  \t\tgroups=['group_id'],\n",
       "  \t\tcenter=True,\n",
       "  \t\tscale_by_group=False,\n",
       "  \t\ttransformation='softplus',\n",
       "  \t\tmethod_kwargs={}\n",
       "  \t), 'categorical_encoders': {'__group_id__group_id': NaNLabelEncoder(add_nan=False, warn=True), 'group_id': NaNLabelEncoder(add_nan=False, warn=True), 'station_loc': NaNLabelEncoder(add_nan=False, warn=True)}, 'scalers': {'latitude': StandardScaler(), 'longitude': StandardScaler(), 'encoder_length': StandardScaler(), 'PM25_center': StandardScaler(), 'PM25_scale': StandardScaler(), 'time_idx': StandardScaler(), 'relative_time_idx': StandardScaler(), 'embedding_1': StandardScaler(), 'embedding_2': StandardScaler(), 'embedding_3': StandardScaler(), 'embedding_4': StandardScaler(), 'embedding_5': StandardScaler(), 'embedding_6': StandardScaler(), 'embedding_7': StandardScaler(), 'embedding_8': StandardScaler(), 'embedding_9': StandardScaler(), 'embedding_10': StandardScaler(), 'embedding_11': StandardScaler(), 'embedding_12': StandardScaler(), 'embedding_13': StandardScaler(), 'embedding_14': StandardScaler(), 'embedding_15': StandardScaler(), 'embedding_16': StandardScaler(), 'embedding_17': StandardScaler(), 'embedding_18': StandardScaler(), 'embedding_19': StandardScaler(), 'embedding_20': StandardScaler(), 'embedding_21': StandardScaler(), 'embedding_22': StandardScaler(), 'embedding_23': StandardScaler(), 'embedding_24': StandardScaler(), 'embedding_25': StandardScaler(), 'embedding_26': StandardScaler(), 'embedding_27': StandardScaler(), 'embedding_28': StandardScaler(), 'embedding_29': StandardScaler(), 'embedding_30': StandardScaler(), 'embedding_31': StandardScaler(), 'embedding_32': StandardScaler()}, 'randomize_length': None, 'predict_mode': False}\n",
       "  \t\"dropout\":                           0.1\n",
       "  \t\"embedding_labels\":                  {'station_loc': {'Alipur, Delhi ': 0, 'Anand Vihar, Delhi ': 1, 'Ashok Vihar, Delhi ': 2, 'Aya Nagar, Delhi ': 3, 'Bawana, Delhi ': 4, 'Burari Crossing, Delhi ': 5, 'CRRI Mathura Road, Delhi ': 6, 'Chandni Chowk, Delhi ': 7, 'DTU, Delhi ': 8, 'Dr. Karni Singh Shooting Range, Delhi ': 9, 'Dwarka Sector 8, Delhi ': 10, 'East Arjun Nagar, Delhi ': 11, 'IGI Airport (T3), Delhi ': 12, 'IHBAS, Dilshad Garden, Delhi ': 13, 'ITO, Delhi ': 14, 'Jahangirpuri, Delhi ': 15, 'Jawaharlal Nehru Stadium, Delhi ': 16, 'Lodhi Road, Delhi ': 17, 'Major Dhyan Chand National Stadium, Delhi ': 18, 'Mandir Marg, Delhi ': 19, 'Mundka, Delhi ': 20, 'NSIT Dwarka, Delhi ': 21, 'Najafgarh, Delhi ': 22, 'Narela, Delhi ': 23, 'Nehru Nagar, Delhi ': 24, 'North Campus, DU, Delhi ': 25, 'Okhla Phase 2, Delhi ': 26, 'Patparganj, Delhi ': 27, 'Punjabi Bagh, Delhi ': 28, 'Pusa, Delhi ': 29, 'R K Puram, Delhi ': 30, 'Rohini, Delhi ': 31, 'Shadipur, Delhi ': 32, 'Sonia Vihar, Delhi ': 33, 'Sri Aurobindo Marg, Delhi ': 34, 'Vivek Vihar, Delhi ': 35, 'Wazirpur, Delhi ': 36}}\n",
       "  \t\"embedding_paddings\":                []\n",
       "  \t\"embedding_sizes\":                   {'station_loc': (37, 12)}\n",
       "  \t\"hidden_continuous_size\":            16\n",
       "  \t\"hidden_continuous_sizes\":           {}\n",
       "  \t\"hidden_size\":                       32\n",
       "  \t\"learning_rate\":                     0.03\n",
       "  \t\"log_gradient_flow\":                 False\n",
       "  \t\"log_interval\":                      10\n",
       "  \t\"log_val_interval\":                  10\n",
       "  \t\"lstm_layers\":                       1\n",
       "  \t\"max_encoder_length\":                72\n",
       "  \t\"monotone_constaints\":               {}\n",
       "  \t\"monotone_constraints\":              {}\n",
       "  \t\"optimizer\":                         adam\n",
       "  \t\"optimizer_params\":                  None\n",
       "  \t\"output_size\":                       7\n",
       "  \t\"output_transformer\":                GroupNormalizer(\n",
       "  \t\tmethod='standard',\n",
       "  \t\tgroups=['group_id'],\n",
       "  \t\tcenter=True,\n",
       "  \t\tscale_by_group=False,\n",
       "  \t\ttransformation='softplus',\n",
       "  \t\tmethod_kwargs={}\n",
       "  \t)\n",
       "  \t\"reduce_on_plateau_min_lr\":          1e-05\n",
       "  \t\"reduce_on_plateau_patience\":        4\n",
       "  \t\"reduce_on_plateau_reduction\":       2.0\n",
       "  \t\"share_single_variable_networks\":    False\n",
       "  \t\"static_categoricals\":               ['station_loc']\n",
       "  \t\"static_reals\":                      ['latitude', 'longitude', 'encoder_length', 'PM25_center', 'PM25_scale']\n",
       "  \t\"time_varying_categoricals_decoder\": []\n",
       "  \t\"time_varying_categoricals_encoder\": []\n",
       "  \t\"time_varying_reals_decoder\":        ['time_idx', 'relative_time_idx']\n",
       "  \t\"time_varying_reals_encoder\":        ['time_idx', 'relative_time_idx', 'PM25', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32']\n",
       "  \t\"weight_decay\":                      0.0\n",
       "  \t\"x_categoricals\":                    ['station_loc']\n",
       "  \t\"x_reals\":                           ['latitude', 'longitude', 'encoder_length', 'PM25_center', 'PM25_scale', 'time_idx', 'relative_time_idx', 'PM25', 'embedding_1', 'embedding_2', 'embedding_3', 'embedding_4', 'embedding_5', 'embedding_6', 'embedding_7', 'embedding_8', 'embedding_9', 'embedding_10', 'embedding_11', 'embedding_12', 'embedding_13', 'embedding_14', 'embedding_15', 'embedding_16', 'embedding_17', 'embedding_18', 'embedding_19', 'embedding_20', 'embedding_21', 'embedding_22', 'embedding_23', 'embedding_24', 'embedding_25', 'embedding_26', 'embedding_27', 'embedding_28', 'embedding_29', 'embedding_30', 'embedding_31', 'embedding_32']\n",
       "  (loss): QuantileLoss(quantiles=[0.02, 0.1, 0.25, 0.5, 0.75, 0.9, 0.98])\n",
       "  (logging_metrics): ModuleList(\n",
       "    (0): SMAPE()\n",
       "    (1): MAE()\n",
       "    (2): RMSE()\n",
       "    (3): MAPE()\n",
       "  )\n",
       "  (input_embeddings): MultiEmbedding(\n",
       "    (embeddings): ModuleDict(\n",
       "      (station_loc): Embedding(37, 12)\n",
       "    )\n",
       "  )\n",
       "  (prescalers): ModuleDict(\n",
       "    (latitude): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (longitude): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (encoder_length): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (PM25_center): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (PM25_scale): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (PM25): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_1): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_2): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_3): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_4): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_5): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_6): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_7): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_8): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_9): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_10): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_11): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_12): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_13): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_14): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_15): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_16): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_17): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_18): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_19): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_20): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_21): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_22): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_23): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_24): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_25): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_26): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_27): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_28): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_29): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_30): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_31): Linear(in_features=1, out_features=16, bias=True)\n",
       "    (embedding_32): Linear(in_features=1, out_features=16, bias=True)\n",
       "  )\n",
       "  (static_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=92, out_features=6, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (fc2): Linear(in_features=6, out_features=6, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=6, out_features=12, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((6,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (station_loc): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (latitude): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (longitude): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (encoder_length): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (PM25_center): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (PM25_scale): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (latitude): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (longitude): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (encoder_length): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (PM25_center): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (PM25_scale): Linear(in_features=1, out_features=16, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (encoder_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((35,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=560, out_features=32, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=32, out_features=32, bias=False)\n",
       "      (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=32, out_features=70, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((35,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (PM25): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_1): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_2): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_3): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_4): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_5): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_6): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_7): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_8): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_9): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_10): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_11): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_12): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_13): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_14): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_15): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_16): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_17): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_18): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_19): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_20): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_21): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_22): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_23): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_24): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_25): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_26): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_27): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_28): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_29): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_30): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_31): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (embedding_32): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (PM25): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_1): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_2): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_3): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_4): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_5): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_6): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_7): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_8): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_9): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_10): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_11): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_12): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_13): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_14): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_15): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_16): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_17): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_18): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_19): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_20): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_21): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_22): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_23): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_24): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_25): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_26): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_27): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_28): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_29): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_30): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_31): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (embedding_32): Linear(in_features=1, out_features=16, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (decoder_variable_selection): VariableSelectionNetwork(\n",
       "    (flattened_grn): GatedResidualNetwork(\n",
       "      (resample_norm): ResampleNorm(\n",
       "        (resample): TimeDistributedInterpolation()\n",
       "        (gate): Sigmoid()\n",
       "        (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=32, out_features=2, bias=True)\n",
       "      (elu): ELU(alpha=1.0)\n",
       "      (context): Linear(in_features=32, out_features=2, bias=False)\n",
       "      (fc2): Linear(in_features=2, out_features=2, bias=True)\n",
       "      (gate_norm): GateAddNorm(\n",
       "        (glu): GatedLinearUnit(\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (fc): Linear(in_features=2, out_features=4, bias=True)\n",
       "        )\n",
       "        (add_norm): AddNorm(\n",
       "          (norm): LayerNorm((2,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (single_variable_grns): ModuleDict(\n",
       "      (time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (relative_time_idx): GatedResidualNetwork(\n",
       "        (resample_norm): ResampleNorm(\n",
       "          (resample): TimeDistributedInterpolation()\n",
       "          (gate): Sigmoid()\n",
       "          (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (elu): ELU(alpha=1.0)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (gate_norm): GateAddNorm(\n",
       "          (glu): GatedLinearUnit(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (fc): Linear(in_features=16, out_features=64, bias=True)\n",
       "          )\n",
       "          (add_norm): AddNorm(\n",
       "            (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (prescalers): ModuleDict(\n",
       "      (time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "      (relative_time_idx): Linear(in_features=1, out_features=16, bias=True)\n",
       "    )\n",
       "    (softmax): Softmax(dim=-1)\n",
       "  )\n",
       "  (static_context_variable_selection): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_initial_hidden_lstm): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_initial_cell_lstm): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (static_context_enrichment): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lstm_encoder): LSTM(32, 32, batch_first=True)\n",
       "  (lstm_decoder): LSTM(32, 32, batch_first=True)\n",
       "  (post_lstm_gate_encoder): GatedLinearUnit(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "  )\n",
       "  (post_lstm_gate_decoder): GatedLinearUnit(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "  )\n",
       "  (post_lstm_add_norm_encoder): AddNorm(\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (post_lstm_add_norm_decoder): AddNorm(\n",
       "    (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (static_enrichment): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (context): Linear(in_features=32, out_features=32, bias=False)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (multihead_attn): InterpretableMultiHeadAttention(\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (v_layer): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (q_layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (k_layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (attention): ScaledDotProductAttention(\n",
       "      (softmax): Softmax(dim=2)\n",
       "    )\n",
       "    (w_h): Linear(in_features=32, out_features=32, bias=False)\n",
       "  )\n",
       "  (post_attn_gate_norm): GateAddNorm(\n",
       "    (glu): GatedLinearUnit(\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "    )\n",
       "    (add_norm): AddNorm(\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (pos_wise_ff): GatedResidualNetwork(\n",
       "    (fc1): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (elu): ELU(alpha=1.0)\n",
       "    (fc2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    (gate_norm): GateAddNorm(\n",
       "      (glu): GatedLinearUnit(\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "      )\n",
       "      (add_norm): AddNorm(\n",
       "        (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_output_gate_norm): GateAddNorm(\n",
       "    (glu): GatedLinearUnit(\n",
       "      (fc): Linear(in_features=32, out_features=64, bias=True)\n",
       "    )\n",
       "    (add_norm): AddNorm(\n",
       "      (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (output_layer): Linear(in_features=32, out_features=7, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Temporal Fusion Transformer model\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    tft_dataset,\n",
    "    learning_rate=0.03,\n",
    "    hidden_size=32,\n",
    "    attention_head_size=1,\n",
    "    dropout=0.1,\n",
    "    hidden_continuous_size=16,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "\n",
    "tft.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is LightningModule: True\n"
     ]
    }
   ],
   "source": [
    "# Verify that the model is a LightningModule\n",
    "print(f\"Model is LightningModule: {isinstance(tft, pl.LightningModule)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_root_dir = os.path.join(os.getcwd(), \"lightning_logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/logger_connector/logger_connector.py:76: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `lightning.pytorch` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n"
     ]
    }
   ],
   "source": [
    "# Configure trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-4, patience=10, verbose=False, mode=\"min\")\n",
    "lr_monitor = LearningRateMonitor(logging_interval=\"epoch\")\n",
    "\n",
    "# Create directory for checkpoints if it doesn't exist\n",
    "import os\n",
    "os.makedirs(\"models\", exist_ok=True)\n",
    "\n",
    "# Updated Trainer initialization for newer PyTorch Lightning versions\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=30,\n",
    "    devices = 1, \n",
    "    accelerator=\"gpu\", \n",
    "    precision= 32,\n",
    "    gradient_clip_val=0.1,\n",
    "    # limit_train_batches=50,\n",
    "    callbacks=[lr_monitor, early_stop_callback],\n",
    "    enable_checkpointing=True,\n",
    "    default_root_dir=\"models/sharded\"  # directory to save checkpoints\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Shard 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439370dc42fa4f3e85a840d663a8a65d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbde5195bc1a43338019f598ff39cb30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f464319a97684598867b09cc8ee57c04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff5e9b86bd4d4a1bb649fca1826c57e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6939f9a5629a4ffbbb86c5c1ad04cee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3b84ec48f8427093d9b8a402d746d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9e2ec092fc49b78c621f8c280b817b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414f1f5800cc47e1921a0bb4bc21dda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10d50c3062048abab7374f135b9a8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "070a34e154a64a9abdf268725a6f88d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60559d852b24f20ac123752999116d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9655d1448504dd0ac094e2d813ae893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375727309bb7411b9a0eb8391cb9de0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c190a0f07b437dae37ffb5c5e8cac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c88aa6fd33864a4688b46c2358833dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f7dd07737024de3bd422b86975394f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c2791122e74367ad06e5a9a3deb186",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1818a5cb2b4beebdbe9a125eb22b1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3700688790034bd39b80f600c0e17883",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2918731ead89445094f77bfe5d13ad9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df564a868ffd49f4a100bc63e47b45c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e21d337e8ef4733b4f66c9ff14d05f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5928992a9d414ba89ec212faa75792c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5762921d16e04f4ba3dea63092bb4294",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff64dbd0af734bf189cb04aef37c4bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2fd9fc30e0b48f9966d8c336c2d7f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b726af2f12ce4d07ae754859959ef737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e08a61684fe417095ba742cb2597f2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23762279e06943fd8d0c6f9419a01b8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a160dc4bf77849498fb27276efc3784a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3014965d90c444b48e094a71517c3bd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8686d534169845c99b10324a6cd24b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Shard 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7747f6242741629b5a2947e0f9e69d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Shard 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc95f12fced24bd691147b83ca92203d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Shard 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8572553ea5c8489593c8eb6e9ce76914",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Shard 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a4f5f98cded46a690ea0ddcd04499b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Shard 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5906db2f878147deaad0008f1cd00dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Shard 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c49a522071546e6a8d4da4afa6f3b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Shard 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cadd7b643c477d8415b6b464f6c65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Shard 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5c841c5b0e442e8b183c7fcb987134c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Shard 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b277919621ab4bc8b7f94ac390a4fa79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Shard 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "478bb119348241899514700fd33b250c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Shard 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ece5d8f188949d78ce83c1dcc30627b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Shard 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab967d9952f34cd886a1477ace51ca92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Shard 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e52180052044da3ba953b1b6d131ac0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Shard 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aca1f86a6a420cbdf82a22a59dcf47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Shard 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445d7d87777246a78a0e8c0b0aca6713",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Shard 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa3aa61b31c45e1a42eeae19c02a5b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Shard 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fedde5a88ae549cc99f6d94a9293a514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Shard 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376e0d13ed254da88deeccf506ed39a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Shard 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4baf08f224c46e38b10cd552dd40390",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Shard 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2566413fa664434a9cb7ee1bb0a01a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Shard 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76bcb481d48a41cd93e02bc4545a8bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Shard 3/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8964f22d0ba40ebb4ce7462f5a5a215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Shard 4/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9c6f113da9645a18712e079c0f59a05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/checkpoint_connector.py:186: .fit(ckpt_path=\"last\") is set, but there is no last checkpoint available. No checkpoint will be loaded. HINT: Set `ModelCheckpoint(..., save_last=True)`.\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/callbacks/model_checkpoint.py:654: Checkpoint directory models/sharded/lightning_logs/version_1/checkpoints exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Shard 5/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "   | Name                               | Type                            | Params | Mode \n",
      "------------------------------------------------------------------------------------------------\n",
      "0  | loss                               | QuantileLoss                    | 0      | train\n",
      "1  | logging_metrics                    | ModuleList                      | 0      | train\n",
      "2  | input_embeddings                   | MultiEmbedding                  | 444    | train\n",
      "3  | prescalers                         | ModuleDict                      | 1.3 K  | train\n",
      "4  | static_variable_selection          | VariableSelectionNetwork        | 9.9 K  | train\n",
      "5  | encoder_variable_selection         | VariableSelectionNetwork        | 86.4 K | train\n",
      "6  | decoder_variable_selection         | VariableSelectionNetwork        | 3.8 K  | train\n",
      "7  | static_context_variable_selection  | GatedResidualNetwork            | 4.3 K  | train\n",
      "8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 4.3 K  | train\n",
      "9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 4.3 K  | train\n",
      "10 | static_context_enrichment          | GatedResidualNetwork            | 4.3 K  | train\n",
      "11 | lstm_encoder                       | LSTM                            | 8.4 K  | train\n",
      "12 | lstm_decoder                       | LSTM                            | 8.4 K  | train\n",
      "13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 2.1 K  | train\n",
      "14 | post_lstm_add_norm_encoder         | AddNorm                         | 64     | train\n",
      "15 | static_enrichment                  | GatedResidualNetwork            | 5.3 K  | train\n",
      "16 | multihead_attn                     | InterpretableMultiHeadAttention | 4.2 K  | train\n",
      "17 | post_attn_gate_norm                | GateAddNorm                     | 2.2 K  | train\n",
      "18 | pos_wise_ff                        | GatedResidualNetwork            | 4.3 K  | train\n",
      "19 | pre_output_gate_norm               | GateAddNorm                     | 2.2 K  | train\n",
      "20 | output_layer                       | Linear                          | 231    | train\n",
      "------------------------------------------------------------------------------------------------\n",
      "155 K     Trainable params\n",
      "0         Non-trainable params\n",
      "155 K     Total params\n",
      "0.620     Total estimated model params size (MB)\n",
      "788       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66739fba4894338a74ffc09defc8ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=30` reached.\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):  # 5 epochs total\n",
    "    for i, stations_shard in enumerate(station_groups):\n",
    "        print(f\"Epoch {epoch}, Shard {i+1}/{len(station_groups)}\")\n",
    "        \n",
    "        # Filter data for current stations\n",
    "        shard_filter = combined_df['station_loc'].isin(stations_shard)\n",
    "        shard_df = combined_df[shard_filter]\n",
    "        \n",
    "        # Create dataset for this shard\n",
    "        shard_dataset = TimeSeriesDataSet(\n",
    "            data=shard_df[lambda x: x.time_idx <= training_cutoff],\n",
    "            time_idx=\"time_idx\",\n",
    "            target=\"PM25\",\n",
    "            group_ids=[\"group_id\"],\n",
    "            min_encoder_length=max_encoder_length // 2,\n",
    "            max_encoder_length=max_encoder_length,\n",
    "            min_prediction_length=1,\n",
    "            max_prediction_length=max_prediction_length,\n",
    "            static_categoricals=[\"station_loc\"],\n",
    "            static_reals=[\"latitude\", \"longitude\"],\n",
    "            time_varying_known_categoricals=[],\n",
    "            time_varying_known_reals=[\"time_idx\"],\n",
    "            time_varying_unknown_categoricals=[],\n",
    "            time_varying_unknown_reals=[\n",
    "                \"PM25\",\n",
    "            ] + [f'embedding_{i}' for i in range(1, embeddings_df.shape[1])],\n",
    "            target_normalizer=GroupNormalizer(\n",
    "                groups=[\"group_id\"], transformation=\"softplus\"\n",
    "            ),\n",
    "            add_relative_time_idx=True,\n",
    "            add_target_scales=True,\n",
    "            add_encoder_length=True,\n",
    "        )\n",
    "        \n",
    "        # Create dataloader\n",
    "        shard_train_dataloader = shard_dataset.to_dataloader(\n",
    "            train=True, \n",
    "            batch_size=batch_size, \n",
    "            num_workers=4,\n",
    "            pin_memory=True\n",
    "        )\n",
    "        \n",
    "        # Train for one epoch on this shard\n",
    "\n",
    "        # try :\n",
    "        #     trainer.fit(\n",
    "        #         tft,\n",
    "        #         train_dataloaders=shard_train_dataloader,\n",
    "        #         val_dataloaders=val_dataloader,\n",
    "        #         ckpt_path=None\n",
    "        #     )\n",
    "\n",
    "        # except Exception as e:\n",
    "\n",
    "        trainer.fit(\n",
    "            tft,\n",
    "            train_dataloaders=shard_train_dataloader,\n",
    "            val_dataloaders=val_dataloader,\n",
    "            ckpt_path=\"last\"  # Continue from previous shard\n",
    "        )\n",
    "        \n",
    "        # Clean up memory\n",
    "        torch.cuda.empty_cache()\n",
    "        del shard_dataset, shard_train_dataloader\n",
    "        \n",
    "    # Save checkpoint at end of each full epoch\n",
    "    trainer.save_checkpoint(f\"models/sharded/tft_air_quality_epoch_{epoch}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3558: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train the model\n",
    "# trainer.fit(\n",
    "#     tft,\n",
    "#     train_dataloaders=train_dataloader,\n",
    "#     val_dataloaders=val_dataloader,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the trained model\n",
    "# trainer.save_checkpoint(\"models/tft_air_quality_forecast_v1.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12156/413610905.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  last_data = combined_df.groupby('station_loc').apply(lambda x: x.iloc[-max_encoder_length:]).reset_index(drop=True)\n",
      "/tmp/ipykernel_12156/413610905.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  last_data = combined_df.groupby('station_loc').apply(lambda x: x.iloc[-max_encoder_length:]).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Get the last available data point for each station\n",
    "last_data = combined_df.groupby('station_loc').apply(lambda x: x.iloc[-max_encoder_length:]).reset_index(drop=True)\n",
    "\n",
    "# Create a prediction dataset\n",
    "pred_dataset = TimeSeriesDataSet(\n",
    "    data=last_data,\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"PM25\",\n",
    "    group_ids=[\"group_id\"],\n",
    "    min_encoder_length=max_encoder_length // 2,  # allow for smaller encoder lengths\n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    static_categoricals=[\"station_loc\"],\n",
    "    static_reals=[\"latitude\", \"longitude\"],\n",
    "    time_varying_known_categoricals=[],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    time_varying_unknown_reals=[\n",
    "        \"PM25\",\n",
    "    ] + [f'embedding_{i}' for i in range(1, embeddings_df.shape[1])],\n",
    "    target_normalizer=GroupNormalizer(\n",
    "        groups=[\"group_id\"], transformation=\"softplus\"\n",
    "    ),\n",
    "    add_relative_time_idx=True,\n",
    "    add_target_scales=True,\n",
    "    add_encoder_length=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/home/naradalinux/miniconda3/envs/graph-tft/lib/python3.9/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=11` in the `DataLoader` to improve performance.\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = tft.predict(pred_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecasting completed. Plots saved to outputs/images/\n"
     ]
    }
   ],
   "source": [
    "output_loc = f\"/home/naradalinux/dev/GCNTFT/outputs/images/{pd.Timestamp.now().strftime('%m%d%H%M')}\"\n",
    "\n",
    "if not os.path.exists(output_loc):\n",
    "    os.makedirs(output_loc)\n",
    "\n",
    "# Plot predictions for each station\n",
    "for station in station_ids:\n",
    "    station_idx = station_mapping[station]\n",
    "    station_preds = predictions[station_idx].detach().cpu().numpy()\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(max_prediction_length), station_preds, label='Prediction')\n",
    "    \n",
    "    # Get historical data for comparison\n",
    "    historical = combined_df[combined_df['station_loc'] == station].tail(max_encoder_length)['PM25'].values\n",
    "    plt.plot(range(-len(historical), 0), historical, label='Historical')\n",
    "    \n",
    "    plt.axvline(x=0, linestyle='--', color='gray')\n",
    "    plt.title(f'24-Hour Air Quality Forecast for Station {station}')\n",
    "    plt.xlabel('Hours')\n",
    "    plt.ylabel('PM25')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Save the plot\n",
    "    \n",
    "    plt.savefig(os.path.join(output_loc, f'station_{station}_forecast.png'))\n",
    "    plt.close()\n",
    "\n",
    "print(\"Forecasting completed. Plots saved to outputs/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph-tft",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
